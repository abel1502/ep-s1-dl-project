{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb900036",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "import typing\n",
    "import json\n",
    "import pathlib\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import transformers\n",
    "import transformers.modeling_outputs\n",
    "import transformers.configuration_utils\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import emoji\n",
    "\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5f873bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_KAGGLE = \"KAGGLE_DOCKER_IMAGE\" in os.environ\n",
    "\n",
    "DATASETS = pathlib.Path(\n",
    "    \".\"\n",
    "    if not IS_KAGGLE\n",
    "    else \"/kaggle/input/influencers-or-observers-predicting-social-roles/Kaggle2025\"\n",
    ")\n",
    "\n",
    "DATASET_TRAIN = DATASETS / \"train.jsonl\"\n",
    "DATASET_KAGGLE = DATASETS / \"kaggle_test.jsonl\"\n",
    "\n",
    "CACHE_DIR = pathlib.Path(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7fc921d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e20b6911",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f28f61",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5e16f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path: pathlib.Path, cache: bool = False) -> pd.DataFrame:\n",
    "    path_pq = (CACHE_DIR / path.name).with_stem(f\"{path.stem}_raw\").with_suffix(\".parquet\")\n",
    "    \n",
    "    if cache and path_pq.exists():\n",
    "        return pd.read_parquet(path_pq)\n",
    "    \n",
    "    # This leaves things to be desired, since there's no way to specify dtypes\n",
    "    # and it assumes float instead of int, causing a loss in precision...\n",
    "    # But I guess it only matters for ids, which we'll probably discard in preprocessing anyway\n",
    "    result = pd.json_normalize(list(map(json.loads, path.read_bytes().splitlines())))\n",
    "    \n",
    "    if cache:\n",
    "        result.to_parquet(path_pq)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "80d1df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_json(DATASET_TRAIN, cache=True)\n",
    "kaggle_data = load_json(DATASET_KAGGLE, cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bcf662",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "4ea7df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # For technical reasons, any text columns we want to use should have no dots in their names.\n",
    "    # The simplest way to achieve this is to replace all dots indiscriminately.\n",
    "    \n",
    "    df = df.rename(columns=lambda x: x.replace(\".\", \"_\"))\n",
    "    \n",
    "    df[\"is_reply\"] = df[\"in_reply_to_status_id\"].notna()\n",
    "    \n",
    "    df = df.drop(columns=[\n",
    "        \"in_reply_to_status_id_str\",\n",
    "        # \"in_reply_to_status_id\",\n",
    "        \"in_reply_to_user_id_str\",\n",
    "        \"in_reply_to_user_id\",\n",
    "        \"quoted_status_id_str\",\n",
    "        \"quoted_status_id\",\n",
    "        \"id_str\",\n",
    "        \"quoted_status_in_reply_to_status_id_str\",\n",
    "        \"quoted_status_in_reply_to_status_id\",\n",
    "        \"quoted_status_in_reply_to_user_id_str\",\n",
    "        \"quoted_status_in_reply_to_user_id\",\n",
    "        \"quoted_status_id_str\",\n",
    "        \"quoted_status_id\",\n",
    "        \"quoted_status_user_id_str\",\n",
    "        \"quoted_status_user_id\",\n",
    "        # \"quoted_status_permalink_expanded\",\n",
    "        \"quoted_status_permalink_display\",\n",
    "        \"quoted_status_permalink_url\",\n",
    "        \"quoted_status_quoted_status_id\",\n",
    "        \"quoted_status_quoted_status_id_str\",\n",
    "        # \"quoted_status_place_id\",\n",
    "        # \"place_id\",\n",
    "        \"lang\",  # Always \"fr\"\n",
    "        \"retweeted\",  # Always False\n",
    "        \"filter_level\",  # Always \"low\"\n",
    "        \"geo\",  # Always None\n",
    "        \"place\",  # Always None\n",
    "        \"coordinates\",  # Always None\n",
    "        \"contributors\",  # Always None\n",
    "        \"quote_count\",  # Always 0\n",
    "        \"reply_count\",  # Always 0\n",
    "        \"retweet_count\",  # Always 0\n",
    "        \"favorite_count\",  # Always 0\n",
    "        \"favorited\",  # Always False\n",
    "        \"quoted_status_geo\",  # Always None\n",
    "        \"quoted_status_place\",  # Always None\n",
    "        \"quoted_status_coordinates\",  # Always None\n",
    "        \"quoted_status_retweeted\",  # Always False\n",
    "        \"quoted_status_filter_level\",  # Always \"low\"\n",
    "        \"quoted_status_contributors\",  # Always None\n",
    "        \"quoted_status_user_utc_offset\",  # Always None\n",
    "        \"quoted_status_user_lang\",  # Always None\n",
    "        \"quoted_status_user_time_zone\",  # Always None\n",
    "        \"quoted_status_user_follow_request_sent\",  # Always None\n",
    "        \"quoted_status_user_following\",  # Always None\n",
    "        \"quoted_status_user_notifications\",  # Always None\n",
    "        \"user_default_profile_image\",  # Always False\n",
    "        \"user_protected\",  # Always False\n",
    "        \"user_contributors_enabled\",  # Always False\n",
    "        \"user_lang\",  # Always None\n",
    "        \"user_notifications\",  # Always None\n",
    "        \"user_following\",  # Always None\n",
    "        \"user_utc_offset\",  # Always None\n",
    "        \"user_time_zone\",  # Always None\n",
    "        \"user_follow_request_sent\",  # Always None\n",
    "    ])\n",
    "    \n",
    "    df[\"full_text\"] = df.apply(lambda tweet: extract_full_text(tweet), axis=1)\n",
    "    \n",
    "    source_split = df[\"source\"].str.removeprefix(\"<a href=\\\"\").str.removesuffix(\"</a>\").str.split(\"\\\" rel=\\\"nofollow\\\">\").map(lambda x: x if len(x) == 2 else pd.NA)\n",
    "    df[\"source_url\"] = source_split.map(lambda x: x[0], na_action=\"ignore\")\n",
    "    df[\"source_name\"] = source_split.map(lambda x: x[1], na_action=\"ignore\")\n",
    "    \n",
    "    df[\"misc_text\"] = df.apply(\n",
    "        lambda x: \"via: {0}; reply: @{1}; quote: @{2} {3}\".format(x[\"source_name\"], x[\"in_reply_to_screen_name\"], x[\"quoted_status_user_screen_name\"], x[\"quoted_status_user_name\"]), axis=1,\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_full_text(tweet: pd.Series) -> str:\n",
    "    text: str = tweet[\"text\"]\n",
    "    \n",
    "    if not pd.isna(tweet[\"extended_tweet_full_text\"]):\n",
    "        text = tweet[\"extended_tweet_full_text\"]\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ab1ee966",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(\"label\", axis=1)\n",
    "y_train = train_data[\"label\"]\n",
    "\n",
    "X_kaggle = kaggle_data\n",
    "\n",
    "X_train = preprocess(X_train)\n",
    "X_kaggle = preprocess(X_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741c8d7e",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "829f7ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03703379602187509"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.full_text.map(emoji.emoji_count, na_action=\"ignore\").corr(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "8e6d12ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_text\n",
       "ðŸ˜‚     4294\n",
       "ðŸ˜­     2457\n",
       "ðŸ¤£     2443\n",
       "ðŸ‘‰     1592\n",
       "ðŸ¤”     1573\n",
       "      ... \n",
       "ðŸ‘¦ðŸ»       1\n",
       "ðŸ¢        1\n",
       "ðŸŒª        1\n",
       "ðŸ§¦        1\n",
       "â˜¢        1\n",
       "Name: count, Length: 1569, dtype: int64"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_freq = X_train.full_text.map(lambda x: [y[\"emoji\"] for y in emoji.emoji_list(x)], na_action=\"ignore\").explode().value_counts()\n",
    "emoji_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "1ae2c0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":backhand_index_pointing_right: in full_text    0.081822\n",
       ":right_arrow: in full_text                      0.069098\n",
       ":red_circle: in full_text                       0.042083\n",
       ":right_arrow_curving_down: in full_text         0.039960\n",
       ":play_button: in full_text                      0.038587\n",
       ":backhand_index_pointing_down: in full_text     0.038319\n",
       ":thinking_face: in full_text                    0.030802\n",
       ":check_mark_button: in full_text                0.027472\n",
       ":warning: in full_text                          0.027041\n",
       ":Canada: in full_text                           0.026622\n",
       ":down_arrow: in full_text                       0.026386\n",
       ":loudly_crying_face: in full_text               0.026133\n",
       ":face_with_medical_mask: in full_text           0.023882\n",
       ":rolling_on_the_floor_laughing: in full_text    0.023686\n",
       ":megaphone: in full_text                        0.022998\n",
       ":police_car_light: in full_text                 0.022880\n",
       ":loudspeaker: in full_text                      0.022859\n",
       ":laptop: in full_text                           0.022122\n",
       ":syringe: in full_text                          0.021717\n",
       ":studio_microphone: in full_text                0.021716\n",
       ":face_vomiting: in full_text                    0.021455\n",
       ":information: in full_text                      0.021393\n",
       ":skull: in full_text                            0.021029\n",
       ":round_pushpin: in full_text                    0.021027\n",
       ":speech_balloon: in full_text                   0.020681\n",
       ":face_with_tears_of_joy: in full_text           0.020457\n",
       ":blue_circle: in full_text                      0.020373\n",
       ":television: in full_text                       0.020276\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_emoji = list(emoji_freq[:512].index)\n",
    "most_relevant_emoji = pd.Series({\n",
    "    f\"{emoji.demojize(em)} in full_text\": X_train.full_text.map(lambda x: em in x, na_action=\"ignore\").corr(y_train)\n",
    "    for em in top_emoji\n",
    "}).abs().sort_values(ascending=False).pipe(lambda x: x[x >= 0.02])\n",
    "\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(most_relevant_emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda51842",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f912dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.load(\"./models/v10/camembertav2-base/text_enc_cache/train.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "5be1585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Made this a class to hold all the caches. It may resemble an nn.Module, but isn't one!\n",
    "class FeatureExtractor:\n",
    "    training: bool\n",
    "    device: torch.device\n",
    "    means: pd.Series | None\n",
    "    stds: pd.Series | None\n",
    "    afm_cache: dict[tuple[str, str], float]\n",
    "    text_encoder_name: str | None\n",
    "    text_tokenizer: nn.Module | None\n",
    "    text_encoder: nn.Module | None\n",
    "    text_config: transformers.configuration_utils.PretrainedConfig | None\n",
    "    text_enc_cache_path: pathlib.Path | None\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        text_encoder_name: str | None = None,\n",
    "        text_enc_cache_path: pathlib.Path | None = None,\n",
    "        device: torch.device = device,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.means = None\n",
    "        self.stds = None\n",
    "        self.afm_cache = {}\n",
    "        self.text_enc_cache_path = text_enc_cache_path\n",
    "        \n",
    "        self.text_encoder_name = text_encoder_name\n",
    "        self.text_tokenizer = None\n",
    "        self.text_encoder = None\n",
    "        self.text_config = None\n",
    "        \n",
    "        if text_encoder_name is not None:\n",
    "            self.text_tokenizer = AutoTokenizer.from_pretrained(text_encoder_name)\n",
    "            if hasattr(self.text_tokenizer, \"to\"):  # Distilbert doesn't, apprently\n",
    "                self.text_tokenizer = self.text_tokenizer.to(self.device)\n",
    "            self.text_encoder = AutoModel.from_pretrained(text_encoder_name).to(self.device)\n",
    "            self.text_config = self.text_encoder.config\n",
    "        \n",
    "        self.train()\n",
    "    \n",
    "    def train(self):\n",
    "        self.training = True\n",
    "    \n",
    "    def eval(self):\n",
    "        self.training = False\n",
    "    \n",
    "    def state_dict(self):\n",
    "        return {\n",
    "            \"means\": self.means,\n",
    "            \"stds\": self.stds,\n",
    "            \"afm_cache\": self.afm_cache,\n",
    "        }\n",
    "    \n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.means = state_dict[\"means\"]\n",
    "        self.stds = state_dict[\"stds\"]\n",
    "        self.afm_cache = state_dict[\"afm_cache\"]\n",
    "    \n",
    "    def dims(self) -> dict[str, int]:\n",
    "        return {\n",
    "            \"md\": len(self.METADATA_FIELDS),\n",
    "            \"substrings\": len(self.SUBSTRINGS),\n",
    "        } | {\n",
    "            field: compress or self.embed_size\n",
    "            for field, compress in self.TEXT_FIELDS\n",
    "        }\n",
    "    \n",
    "    @property\n",
    "    def embed_size(self) -> int:\n",
    "        return self.text_config.hidden_size\n",
    "    \n",
    "    def extract(self, df: pd.DataFrame, override_cache: bool = False) -> dict[str, torch.Tensor]:\n",
    "        result: dict[str, torch.Tensor] = {}\n",
    "        \n",
    "        if self.text_enc_cache_path is None:\n",
    "            self._extract(df, result)\n",
    "            return result\n",
    "        \n",
    "        cf = self.text_enc_cache_path / (\"train.ckpt\" if self.training else \"infer.ckpt\")\n",
    "        cf.parent.mkdir(parents=True, exist_ok=True)\n",
    "        if cf.exists() and not override_cache:\n",
    "            encodings: dict[str, torch.Tensor] = torch.load(cf)\n",
    "            for col_name, value in encodings.items():\n",
    "                result[col_name] = value.to(self.device)\n",
    "        \n",
    "        keys_pre = len(result)\n",
    "        self._extract(df, result)\n",
    "        keys_post = len(result)\n",
    "        \n",
    "        if keys_post > keys_pre:\n",
    "            torch.save({\n",
    "                field: embedding.cpu().detach()\n",
    "                for field, embedding in result.items()\n",
    "            }, cf)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _extract(self, df: pd.DataFrame, result: dict[str, torch.Tensor]):\n",
    "        if \"md\" not in result:\n",
    "            result[\"md\"] = self.extract_raw_metadata(df)\n",
    "        \n",
    "        if \"substrings\" not in result:\n",
    "            result[\"substrings\"] = torch.tensor([df[\"full_text\"].str.contains(x) for x in self.SUBSTRINGS], dtype=torch.float32, device=self.device).T\n",
    "        \n",
    "        for col_name, compress in self.TEXT_FIELDS:\n",
    "            if col_name in result:\n",
    "                continue\n",
    "            \n",
    "            emb = self.embed_texts(df[col_name])\n",
    "            \n",
    "            if compress is not None and compress < emb.shape[1]:\n",
    "                pca = PCA(n_components=compress)\n",
    "                emb = pca.fit_transform(emb.cpu().detach().numpy())\n",
    "                emb = torch.tensor(emb, dtype=torch.float32, device=self.device)\n",
    "            elif compress is not None:\n",
    "                print(f\"Warning: embedding for {col_name} zero-padded from {emb.shape[1]} to {compress}, consider reducing requested size\")\n",
    "                emb = torch.nn.functional.pad(emb, (0, compress - emb.shape[1]))\n",
    "            \n",
    "            result[col_name] = emb\n",
    "    \n",
    "    def extract_raw_metadata(self, df: pd.DataFrame) -> torch.Tensor:\n",
    "        md_cols: list[pd.Series] = []\n",
    "\n",
    "        for fn, col_name in tqdm(self.METADATA_FIELDS, desc=\"Extracting metadata\"):\n",
    "            md_cols.append(fn(self, df[col_name]))\n",
    "        \n",
    "        md: pd.DataFrame = pd.concat(md_cols, axis=1)\n",
    "        \n",
    "        # The second case shouldn't be triggered, but sometimes the preprocessor used during training is lost\n",
    "        if self.training:\n",
    "            self.means = md.mean().fillna(0)\n",
    "            self.stds = md.std().fillna(1)\n",
    "        \n",
    "        assert self.means is not None and self.stds is not None, \"You forgot to train/load the feature extractor\"\n",
    "\n",
    "        md = (md - self.means) / self.stds\n",
    "\n",
    "        return torch.from_numpy(md.to_numpy()).float().to(self.device)\n",
    "\n",
    "    def embed_texts(\n",
    "        self,\n",
    "        texts: pd.Series,\n",
    "        batch_size: int = 64,\n",
    "        progress: bool = True\n",
    "    ) -> torch.Tensor:\n",
    "        tokenizer = self.text_tokenizer\n",
    "        encoder = self.text_encoder\n",
    "        encoder.eval()\n",
    "\n",
    "        all_embeddings = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_offsets = range(0, len(texts), batch_size)\n",
    "            if progress:\n",
    "                batch_offsets = tqdm(batch_offsets, desc=f\"Embedding {texts.name or '<unnamed>'}\")\n",
    "            for i in batch_offsets:\n",
    "                batch_texts = texts.iloc[i:i + batch_size]\n",
    "                nonna = batch_texts.notna() & batch_texts.str.len().gt(0)\n",
    "\n",
    "                tokenized = tokenizer(\n",
    "                    batch_texts[nonna].tolist(),\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    return_tensors=\"pt\",\n",
    "                    max_length=self.text_config.max_position_embeddings\n",
    "                ).to(self.device)\n",
    "\n",
    "                outputs: transformers.modeling_outputs.BaseModelOutput = encoder(**tokenized)\n",
    "                last_hidden: torch.Tensor = outputs.last_hidden_state\n",
    "                mask: torch.Tensor = tokenized[\"attention_mask\"].unsqueeze(-1)\n",
    "                \n",
    "                masked_hidden = last_hidden * mask\n",
    "                summed = masked_hidden.sum(dim=1)\n",
    "                counts = mask.sum(dim=1)\n",
    "                embeddings = torch.zeros(len(batch_texts), last_hidden.shape[2], device=self.device)\n",
    "                nonna = nonna.reset_index(drop=True)\n",
    "                embeddings[nonna[nonna].index] = (summed / counts)\n",
    "\n",
    "                all_embeddings.append(embeddings)\n",
    "\n",
    "        return torch.cat(all_embeddings, dim=0)\n",
    "    \n",
    "    def apply_fill_mean(\n",
    "        self,\n",
    "        col: pd.Series,\n",
    "        func: typing.Callable[[typing.Any], typing.Any],\n",
    "    ) -> pd.Series:\n",
    "        col = col.map(func, na_action=\"ignore\")\n",
    "        \n",
    "        key = (col.name, func.__name__)\n",
    "        if self.training:\n",
    "            self.afm_cache[key] = col.mean()\n",
    "        assert key in self.afm_cache, \"You forgot to train/load the feature extractor\"\n",
    "        \n",
    "        return col.fillna(self.afm_cache[key])\n",
    "    \n",
    "    def md_bool(self, col: pd.Series) -> pd.Series:\n",
    "        return col.map(lambda x: (1 if x else -1), na_action=\"ignore\").fillna(0)\n",
    "\n",
    "    def md_len(self, col: pd.Series) -> pd.Series:\n",
    "        return col.map(len, na_action=\"ignore\").fillna(0)\n",
    "\n",
    "    def md_time(self, col: pd.Series) -> pd.Series:\n",
    "        return self.apply_fill_mean(col, lambda x: time.mktime(time.strptime(x, \"%a %b %d %H:%M:%S %z %Y\")))\n",
    "\n",
    "    def md_num(self, col: pd.Series) -> pd.Series:\n",
    "        return self.apply_fill_mean(col, pd.to_numeric)\n",
    "\n",
    "    def md_place(self, col: pd.Series) -> pd.Series:\n",
    "        return col.map(lambda x: int(x, 16), na_action=\"ignore\").fillna(0)\n",
    "    \n",
    "    METADATA_FIELDS: list[tuple[typing.Callable[[FeatureExtractor, pd.Series], pd.Series], str]] = [\n",
    "        (md_bool, \"is_quote_status\"),\n",
    "        (md_bool, \"is_reply\"),\n",
    "        (md_bool, \"possibly_sensitive\"),\n",
    "        (md_bool, \"quoted_status_user_verified\"),\n",
    "        (md_bool, \"user_is_translator\"),\n",
    "        (md_bool, \"user_geo_enabled\"),\n",
    "        (md_bool, \"user_profile_use_background_image\"),\n",
    "        (md_bool, \"user_default_profile\"),\n",
    "        \n",
    "        (md_len, \"full_text\"),\n",
    "        (md_len, \"source_name\"),\n",
    "        (md_len, \"in_reply_to_screen_name\"),\n",
    "        (md_len, \"quoted_status_extended_tweet_entities_urls\"),\n",
    "        (md_len, \"quoted_status_extended_tweet_entities_user_mentions\"),\n",
    "        (md_len, \"quoted_status_extended_tweet_full_text\"),\n",
    "        (md_len, \"quoted_status_entities_urls\"),\n",
    "        (md_len, \"quoted_status_user_profile_image_url_https\"),\n",
    "        (md_len, \"quoted_status_user_profile_background_image_url\"),\n",
    "        (md_len, \"quoted_status_user_profile_background_image_url_https\"),\n",
    "        (md_len, \"quoted_status_user_screen_name\"),\n",
    "        (md_len, \"quoted_status_user_name\"),\n",
    "        (md_len, \"entities_hashtags\"),\n",
    "        (md_len, \"entities_user_mentions\"),\n",
    "        (md_len, \"user_profile_image_url_https\"),\n",
    "        (md_len, \"user_profile_background_image_url\"),\n",
    "        (md_len, \"user_description\"),\n",
    "        (md_len, \"user_translator_type\"),\n",
    "        (md_len, \"user_url\"),\n",
    "        (md_len, \"user_profile_banner_url\"),\n",
    "        (md_len, \"user_location\"),\n",
    "        (md_len, \"display_text_range\"),\n",
    "        (md_len, \"extended_tweet_entities_urls\"),\n",
    "        (md_len, \"extended_tweet_entities_hashtags\"),\n",
    "        (md_len, \"extended_tweet_entities_user_mentions\"),\n",
    "        (md_len, \"quoted_status_permalink_expanded\"),\n",
    "        \n",
    "        (md_time, \"created_at\"),\n",
    "        (md_time, \"user_created_at\"),\n",
    "        (md_time, \"quoted_status_created_at\"),\n",
    "        (md_time, \"quoted_status_user_created_at\"),\n",
    "        \n",
    "        (md_num, \"user_statuses_count\"),\n",
    "        (md_num, \"user_listed_count\"),\n",
    "        (md_num, \"user_favourites_count\"),\n",
    "        (md_num, \"user_profile_background_tile\"),\n",
    "        (md_num, \"quoted_status_quote_count\"),\n",
    "        (md_num, \"quoted_status_user_followers_count\"),\n",
    "        (md_num, \"quoted_status_user_favourites_count\"),\n",
    "        (md_num, \"in_reply_to_status_id\"),\n",
    "        \n",
    "        (md_place, \"quoted_status_place_id\"),\n",
    "        (md_place, \"place_id\"),\n",
    "    ]\n",
    "\n",
    "    TEXT_FIELDS: list[tuple[str, int | None]] = [\n",
    "        (\"full_text\", None),\n",
    "        (\"user_description\", 64),\n",
    "        (\"misc_text\", None),\n",
    "        # (\"source_name\", None),\n",
    "        # (\"in_reply_to_screen_name\", None),\n",
    "        # (\"quoted_status_user_screen_name\", None),\n",
    "        # (\"quoted_status_user_name\", None),\n",
    "    ]\n",
    "    \n",
    "    SUBSTRINGS: list[str] = list(most_relevant_emoji.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1bc90d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    features: dict[str, torch.Tensor]\n",
    "    labels: torch.Tensor\n",
    "    device: torch.device\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_extractor: FeatureExtractor,\n",
    "        df: pd.DataFrame,\n",
    "        labels: pd.Series,\n",
    "        device: torch.device = device,\n",
    "    ):\n",
    "        self.features = feature_extractor.extract(df)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features[\"md\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"features\": {key: val[idx] for key, val in self.features.items()},\n",
    "            \"label\": self.labels[idx],\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    features = {\n",
    "        key: torch.stack([x[\"features\"][key] for x in batch])\n",
    "        for key in batch[0][\"features\"].keys()\n",
    "    }\n",
    "    labels = torch.stack([x[\"label\"] for x in batch])\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "\n",
    "class TweetClassifier(nn.Module):\n",
    "    feature_sizes: dict[str, int]\n",
    "    \n",
    "    layer1: nn.ModuleDict\n",
    "    fc2: nn.Linear\n",
    "    fc3: nn.Linear\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_sizes: dict[str, int],\n",
    "        hidden_dim: int = 512,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_sizes = feature_sizes\n",
    "        \n",
    "        self.layer1 = nn.ModuleDict()\n",
    "        \n",
    "        def _add(name, dropout: float):\n",
    "            self.layer1[name] = nn.Sequential(\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(feature_sizes[name], hidden_dim),\n",
    "            )\n",
    "        \n",
    "        _add(\"md\", 0.1)\n",
    "        _add(\"substrings\", 0.1)\n",
    "        _add(\"full_text\", 0.1)\n",
    "        _add(\"user_description\", 0.4)\n",
    "        _add(\"misc_text\", 0.3)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, NUM_CLASSES)\n",
    "    \n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return next(self.parameters()).device\n",
    "    \n",
    "    def forward(self, features: dict[str, torch.Tensor]) -> dict[str, torch.Tensor]:\n",
    "        batch_size = len(features[\"md\"])\n",
    "        \n",
    "        x = torch.zeros(batch_size, self.fc2.in_features, device=self.device)\n",
    "        \n",
    "        for name, module in self.layer1.items():\n",
    "            x += module(features[name])\n",
    "\n",
    "        x = F.relu(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        logits = self.fc3(x)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "        return {\n",
    "            \"logits\": logits,\n",
    "            \"probs\": probs,\n",
    "            \"log_probs\": log_probs,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c7a47ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: TweetClassifier,\n",
    "    train_ds: Dataset,\n",
    "    val_ds: Dataset,\n",
    "    epochs: int = 3,\n",
    "    lr: float = 2e-4,\n",
    "    weight_decay: float = 0.01,  # TODO: Lower?\n",
    "    max_grad_norm: float = 1.0,\n",
    "    device: torch.device = device,\n",
    "    batch_size: int = 32,\n",
    "    optimizer: torch.optim.Optimizer | None = None,\n",
    "    checkpoints_path: pathlib.Path | str | None = \".\",\n",
    "    return_best: bool = False,\n",
    ") -> TweetClassifier:\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    \n",
    "    model.to(device)\n",
    "    if optimizer is None:\n",
    "        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_file: pathlib.Path | None = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{epochs}\")\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        status_bar = tqdm(train_loader, desc=\"Training\")\n",
    "\n",
    "        for features, labels in status_bar:\n",
    "            features: dict[str, torch.Tensor]\n",
    "            labels: torch.Tensor\n",
    "            features = {k: v.to(device) for k, v in features.items()}\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            out = model(features)\n",
    "            logits = out[\"logits\"]\n",
    "            \n",
    "            loss: torch.Tensor = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            status_bar.set_postfix({\"loss\": total_loss / (status_bar.n + 1)})\n",
    "        \n",
    "        print(f\"Train Loss: {total_loss / len(train_loader):.4f}\")\n",
    "        \n",
    "        val_metrics = evaluate_model(\n",
    "            model=model,\n",
    "            val_ds=val_ds,\n",
    "            device=device,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        print(f\"Val Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['acc']:.4f}\")\n",
    "\n",
    "        if checkpoints_path is not None:\n",
    "            ckpt = pathlib.Path(checkpoints_path) / f\"epoch_{epoch:02}.pt\"\n",
    "            torch.save(model.state_dict(), ckpt)\n",
    "            print(f\"Checkpoint saved to {ckpt}\")\n",
    "            \n",
    "            if val_metrics[\"loss\"] < best_val_loss:\n",
    "                best_val_loss = val_metrics[\"loss\"]\n",
    "                best_model_file = ckpt\n",
    "\n",
    "    if return_best and best_model_file is not None:\n",
    "        print(f\"Best model: {best_model_file}\")\n",
    "        model.load_state_dict(torch.load(best_model_file))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: TweetClassifier,\n",
    "    val_ds: Dataset,\n",
    "    device: torch.device = device,\n",
    "    batch_size: int = 32,\n",
    ") -> tuple[float, float]:\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        status_bar = tqdm(val_loader, desc=\"Evaluating\")\n",
    "        \n",
    "        for features, labels in status_bar:\n",
    "            features: dict[str, torch.Tensor]\n",
    "            labels: torch.Tensor\n",
    "            features = {k: v.to(device) for k, v in features.items()}\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            out = model(features)\n",
    "            logits: torch.Tensor = out[\"logits\"]\n",
    "            \n",
    "            loss: torch.Tensor = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            count += labels.size(0)\n",
    "            \n",
    "            status_bar.set_postfix({\"loss\": total_loss / (status_bar.n + 1), \"acc\": correct / count})\n",
    "\n",
    "    return {\n",
    "        \"loss\": total_loss / len(val_loader),\n",
    "        \"acc\": correct / count,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "558a176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_with_model(\n",
    "    model: TweetClassifier,\n",
    "    feature_extractor: FeatureExtractor,\n",
    "    df: pd.DataFrame,\n",
    "    out_file: pathlib.Path | str | None = None,\n",
    "    device: torch.device = device,\n",
    "    batch_size: int = 32,\n",
    ") -> pd.Series:\n",
    "    feature_extractor.eval()\n",
    "    \n",
    "    data_loader = DataLoader(\n",
    "        TweetDataset(feature_extractor, df, torch.zeros(len(df), dtype=torch.long, device=device), device=device),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    predictions = torch.zeros(len(df), dtype=torch.long)\n",
    "    cur_idx = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, _ in tqdm(data_loader, desc=\"Inferring\"):\n",
    "            features: dict[str, torch.Tensor]\n",
    "            features = {k: v.to(device) for k, v in features.items()}\n",
    "\n",
    "            out = model(features)\n",
    "            logits: torch.Tensor = out[\"logits\"].cpu()\n",
    "            \n",
    "            predictions[cur_idx:cur_idx+len(features[\"md\"])] = logits.argmax(dim=-1)\n",
    "            cur_idx += len(features[\"md\"])\n",
    "    \n",
    "    df = df.copy()\n",
    "    df[\"pred_label\"] = pd.Series(predictions).astype(int)\n",
    "\n",
    "    # Reconciliation between same users\n",
    "    # Note: the pandas implementation OOM-ed, but the pure python one seems a lot slower\n",
    "    # TODO: Also directly copy the answers from the training set for any shared user\n",
    "    # TODO: Optimize this by precomputing a short \"user_id\", in a sense\n",
    "    same_user_key = [\"user_created_at\", \"user_profile_image_url\"]\n",
    "    per_user_stats: dict[tuple[str, str], list[int]] = dict()\n",
    "    for _, row in df.iterrows():\n",
    "        per_user_stats.setdefault(tuple(row[same_user_key].tolist()), [0, 0])[int(row[\"pred_label\"])] += 1\n",
    "    \n",
    "    per_user_correct: dict[tuple[str, str], int] = dict()\n",
    "    for key, stats in per_user_stats.items():\n",
    "        if stats[0] == 0 or stats[1] == 0:\n",
    "            continue\n",
    "        \n",
    "        per_user_correct[key] = np.select(\n",
    "            [stats[0] > stats[1], stats[1] > stats[0]],\n",
    "            [0, 1],\n",
    "            default=np.random.randint(0, 2),\n",
    "        )\n",
    "    \n",
    "    del per_user_stats\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        key = tuple(row[same_user_key].tolist())\n",
    "        if key in per_user_correct:\n",
    "            per_user_correct[key]\n",
    "            df.at[idx, \"pred_label\"] = per_user_correct[key]\n",
    "    \n",
    "    if out_file is not None:\n",
    "        output = df[[\"challenge_id\", \"pred_label\"]]\n",
    "        output.columns = [\"ID\", \"Prediction\"]\n",
    "        output.to_csv(out_file, index=False)\n",
    "    \n",
    "    return df[\"pred_label\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4957dd8c",
   "metadata": {},
   "source": [
    "# Test runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d9ff6068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== [ almanach/camembertav2-base ] =====\n",
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:18<00:00, 117.11it/s, loss=0.467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 180.89it/s, loss=0.44, acc=0.804] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4277, Acc: 0.8044\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_01.pt\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:18<00:00, 115.28it/s, loss=0.432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 170.50it/s, loss=0.423, acc=0.81] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4181, Acc: 0.8101\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_02.pt\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:19<00:00, 111.78it/s, loss=0.42] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 168.63it/s, loss=0.404, acc=0.82] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4024, Acc: 0.8202\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_03.pt\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:19<00:00, 109.56it/s, loss=0.412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 164.94it/s, loss=0.427, acc=0.821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3956, Acc: 0.8212\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_04.pt\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:22<00:00, 98.54it/s, loss=0.407] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 155.61it/s, loss=0.395, acc=0.825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3904, Acc: 0.8249\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_05.pt\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:19<00:00, 109.08it/s, loss=0.401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 161.79it/s, loss=0.415, acc=0.825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3890, Acc: 0.8252\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_06.pt\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:20<00:00, 105.26it/s, loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 166.06it/s, loss=0.405, acc=0.826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3930, Acc: 0.8262\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_07.pt\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:20<00:00, 104.03it/s, loss=0.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 157.75it/s, loss=0.385, acc=0.828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3848, Acc: 0.8279\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_08.pt\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:20<00:00, 105.26it/s, loss=0.384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 163.34it/s, loss=0.41, acc=0.825] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3897, Acc: 0.8247\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_09.pt\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:20<00:00, 105.10it/s, loss=0.376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 159.43it/s, loss=0.395, acc=0.827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3888, Acc: 0.8267\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_10.pt\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:22<00:00, 98.60it/s, loss=0.371] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 148.49it/s, loss=0.385, acc=0.832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3751, Acc: 0.8321\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_11.pt\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:22<00:00, 97.01it/s, loss=0.366] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 153.40it/s, loss=0.398, acc=0.834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3736, Acc: 0.8341\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_12.pt\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:22<00:00, 95.42it/s, loss=0.36]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 143.72it/s, loss=0.387, acc=0.835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3755, Acc: 0.8349\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_13.pt\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:23<00:00, 92.98it/s, loss=0.352] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 144.98it/s, loss=0.38, acc=0.84]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3679, Acc: 0.8395\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_14.pt\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:23<00:00, 93.65it/s, loss=0.347] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 144.56it/s, loss=0.377, acc=0.837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3694, Acc: 0.8369\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_15.pt\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:23<00:00, 93.46it/s, loss=0.339] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 143.12it/s, loss=0.381, acc=0.84] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3736, Acc: 0.8400\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_16.pt\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:23<00:00, 93.56it/s, loss=0.333] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 142.55it/s, loss=0.381, acc=0.84] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3688, Acc: 0.8400\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_17.pt\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:23<00:00, 93.38it/s, loss=0.327] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 136.43it/s, loss=0.366, acc=0.84] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3662, Acc: 0.8405\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_18.pt\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:23<00:00, 93.49it/s, loss=0.322] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 141.39it/s, loss=0.404, acc=0.833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3840, Acc: 0.8334\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_19.pt\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2179/2179 [00:23<00:00, 93.39it/s, loss=0.316] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243/243 [00:01<00:00, 145.14it/s, loss=0.373, acc=0.842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3680, Acc: 0.8416\n",
      "Checkpoint saved to models\\v11\\camembertav2-base\\epoch_20.pt\n",
      "Best model: models\\v11\\camembertav2-base\\epoch_18.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abel\\AppData\\Local\\Temp\\ipykernel_8008\\3880069523.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
      "Inferring: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1616/1616 [00:06<00:00, 263.94it/s]\n"
     ]
    }
   ],
   "source": [
    "text_encoder_name = \"almanach/camembertav2-base\"\n",
    "print(f\"\\n===== [ {text_encoder_name} ] =====\\n\")\n",
    "\n",
    "model_folder = pathlib.Path(\"./models/v11/\") / text_encoder_name.split(\"/\")[-1]\n",
    "model_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "feature_extractor = FeatureExtractor(text_encoder_name=text_encoder_name, text_enc_cache_path=model_folder / \"text_enc_cache\", device=device)\n",
    "feature_extractor.train()\n",
    "\n",
    "f_ext_ckpt = model_folder / \"feature_extractor.ckpt\"\n",
    "if f_ext_ckpt.exists():\n",
    "    feature_extractor.load_state_dict(torch.load(f_ext_ckpt, weights_only=False))  # This has a pd.Series in it, so otherwise torch 2.6+ complains\n",
    "\n",
    "full_train_ds = TweetDataset(feature_extractor, X_train, y_train, device=device)\n",
    "\n",
    "torch.save(feature_extractor.state_dict(), f_ext_ckpt)\n",
    "\n",
    "train_ds, val_ds = random_split(full_train_ds, [0.9, 0.1], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "model = TweetClassifier(\n",
    "    feature_sizes=feature_extractor.dims(),\n",
    "    hidden_dim=512,\n",
    ").to(device)\n",
    "\n",
    "model = train_model(model, train_ds, val_ds, lr=2e-4, epochs=20, batch_size=64, device=device, checkpoints_path=model_folder, return_best=True)\n",
    "torch.save(model.state_dict(), model_folder / \"best_model.ckpt\")\n",
    "torch.cuda.empty_cache()\n",
    "infer_with_model(model, feature_extractor, X_kaggle, batch_size=64, device=device, out_file=model_folder / \"predictions-v11.csv\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4ad414f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abel\\AppData\\Local\\Temp\\ipykernel_8008\\3880069523.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
      "Inferring: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1616/1616 [00:05<00:00, 313.09it/s]\n"
     ]
    }
   ],
   "source": [
    "model_folder = pathlib.Path(\"./models/v11/camembertav2-base/\")\n",
    "feature_extractor = FeatureExtractor(text_encoder_name=\"almanach/camembertav2-base\", text_enc_cache_path=model_folder / \"text_enc_cache\", device=device)\n",
    "feature_extractor.load_state_dict(torch.load(model_folder / \"feature_extractor.ckpt\", weights_only=False))\n",
    "model = TweetClassifier(\n",
    "    feature_sizes=feature_extractor.dims(),\n",
    "    hidden_dim=512,\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(model_folder / \"epoch_20.pt\"))\n",
    "good_predictions = infer_with_model(model, feature_extractor, X_kaggle, batch_size=64, device=device, out_file=model_folder / \"predictions-v11-e20.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
