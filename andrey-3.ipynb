{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb900036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import typing\n",
    "import json\n",
    "import pathlib\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import AdamW\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import transformers\n",
    "import transformers.modeling_outputs\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import sklearn\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f873bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_KAGGLE = \"KAGGLE_DOCKER_IMAGE\" in os.environ\n",
    "\n",
    "DATASETS = pathlib.Path(\n",
    "    \".\"\n",
    "    if not IS_KAGGLE\n",
    "    else \"/kaggle/input/influencers-or-observers-predicting-social-roles/Kaggle2025\"\n",
    ")\n",
    "\n",
    "DATASET_TRAIN = DATASETS / \"train.jsonl\"\n",
    "DATASET_KAGGLE = DATASETS / \"kaggle_test.jsonl\"\n",
    "\n",
    "CACHE_DIR = pathlib.Path(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7fc921d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e20b6911",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f28f61",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e16f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path: pathlib.Path, cache: bool = False) -> pd.DataFrame:\n",
    "    path_pq = (CACHE_DIR / path.name).with_stem(f\"{path.stem}_raw\").with_suffix(\".parquet\")\n",
    "    \n",
    "    if cache and path_pq.exists():\n",
    "        return pd.read_parquet(path_pq)\n",
    "    \n",
    "    # This leaves things to be desired, since there's no way to specify dtypes\n",
    "    # and it assumes float instead of int, causing a loss in precision...\n",
    "    # But I guess it only matters for ids, which we'll probably discard in preprocessing anyway\n",
    "    result = pd.json_normalize(list(map(json.loads, path.read_bytes().splitlines())))\n",
    "    \n",
    "    if cache:\n",
    "        result.to_parquet(path_pq)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80d1df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_json(DATASET_TRAIN, cache=True)\n",
    "kaggle_data = load_json(DATASET_KAGGLE, cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bcf662",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ea7df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"is_reply\"] = df[\"in_reply_to_status_id\"].notna()\n",
    "    \n",
    "    df = df.drop(columns=[\n",
    "        \"in_reply_to_status_id_str\",\n",
    "        # \"in_reply_to_status_id\",\n",
    "        \"in_reply_to_user_id_str\",\n",
    "        \"in_reply_to_user_id\",\n",
    "        \"quoted_status_id_str\",\n",
    "        \"quoted_status_id\",\n",
    "        \"id_str\",\n",
    "        \"quoted_status.in_reply_to_status_id_str\",\n",
    "        \"quoted_status.in_reply_to_status_id\",\n",
    "        \"quoted_status.in_reply_to_user_id_str\",\n",
    "        \"quoted_status.in_reply_to_user_id\",\n",
    "        \"quoted_status.id_str\",\n",
    "        \"quoted_status.id\",\n",
    "        \"quoted_status.user.id_str\",\n",
    "        \"quoted_status.user.id\",\n",
    "        # \"quoted_status_permalink.expanded\",\n",
    "        \"quoted_status_permalink.display\",\n",
    "        \"quoted_status_permalink.url\",\n",
    "        \"quoted_status.quoted_status_id\",\n",
    "        \"quoted_status.quoted_status_id_str\",\n",
    "        # \"quoted_status.place.id\",\n",
    "        # \"place.id\",\n",
    "        \"lang\",  # Always \"fr\"\n",
    "        \"retweeted\",  # Always False\n",
    "        \"filter_level\",  # Always \"low\"\n",
    "        \"geo\",  # Always None\n",
    "        \"place\",  # Always None\n",
    "        \"coordinates\",  # Always None\n",
    "        \"contributors\",  # Always None\n",
    "        \"quote_count\",  # Always 0\n",
    "        \"reply_count\",  # Always 0\n",
    "        \"retweet_count\",  # Always 0\n",
    "        \"favorite_count\",  # Always 0\n",
    "        \"favorited\",  # Always False\n",
    "        \"quoted_status.geo\",  # Always None\n",
    "        \"quoted_status.place\",  # Always None\n",
    "        \"quoted_status.coordinates\",  # Always None\n",
    "        \"quoted_status.retweeted\",  # Always False\n",
    "        \"quoted_status.filter_level\",  # Always \"low\"\n",
    "        \"quoted_status.contributors\",  # Always None\n",
    "        \"quoted_status.user.utc_offset\",  # Always None\n",
    "        \"quoted_status.user.lang\",  # Always None\n",
    "        \"quoted_status.user.time_zone\",  # Always None\n",
    "        \"quoted_status.user.follow_request_sent\",  # Always None\n",
    "        \"quoted_status.user.following\",  # Always None\n",
    "        \"quoted_status.user.notifications\",  # Always None\n",
    "        \"user.default_profile_image\",  # Always False\n",
    "        \"user.protected\",  # Always False\n",
    "        \"user.contributors_enabled\",  # Always False\n",
    "        \"user.lang\",  # Always None\n",
    "        \"user.notifications\",  # Always None\n",
    "        \"user.following\",  # Always None\n",
    "        \"user.utc_offset\",  # Always None\n",
    "        \"user.time_zone\",  # Always None\n",
    "        \"user.follow_request_sent\",  # Always None\n",
    "    ])\n",
    "    \n",
    "    df[\"full_text\"] = df.apply(lambda tweet: extract_full_text(tweet), axis=1)\n",
    "    \n",
    "    source_split = df[\"source\"].str.removeprefix(\"<a href=\\\"\").str.removesuffix(\"</a>\").str.split(\"\\\" rel=\\\"nofollow\\\">\").map(lambda x: x if len(x) == 2 else pd.NA)\n",
    "    df[\"source.url\"] = source_split.map(lambda x: x[0], na_action=\"ignore\")\n",
    "    df[\"source.name\"] =source_split.map(lambda x: x[1], na_action=\"ignore\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_full_text(tweet: pd.Series) -> str:\n",
    "    text: str = tweet[\"text\"]\n",
    "    \n",
    "    if not pd.isna(tweet[\"extended_tweet.full_text\"]):\n",
    "        text = tweet[\"extended_tweet.full_text\"]\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab1ee966",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(\"label\", axis=1)\n",
    "y_train = train_data[\"label\"]\n",
    "\n",
    "X_kaggle = kaggle_data\n",
    "\n",
    "X_train = preprocess(X_train)\n",
    "X_kaggle = preprocess(X_kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eaec88",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3850a86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "in_reply_to_status_id_str                 -0.050524\n",
       "in_reply_to_status_id                     -0.050524\n",
       "in_reply_to_user_id_str                   -0.008360\n",
       "in_reply_to_user_id                       -0.008360\n",
       "quoted_status_id_str                      -0.019543\n",
       "quoted_status_id                          -0.019543\n",
       "id_str                                    -0.026025\n",
       "quoted_status.in_reply_to_status_id_str   -0.029068\n",
       "quoted_status.in_reply_to_status_id       -0.029068\n",
       "quoted_status.in_reply_to_user_id_str     -0.026719\n",
       "quoted_status.in_reply_to_user_id         -0.026719\n",
       "quoted_status.id_str                      -0.019542\n",
       "quoted_status.id                          -0.019542\n",
       "quoted_status.user.id_str                  0.018087\n",
       "quoted_status.user.id                      0.018087\n",
       "quoted_status.quoted_status_id            -0.022994\n",
       "quoted_status.quoted_status_id_str        -0.022994\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[[\n",
    "    \"in_reply_to_status_id_str\",\n",
    "    \"in_reply_to_status_id\",\n",
    "    \"in_reply_to_user_id_str\",\n",
    "    \"in_reply_to_user_id\",\n",
    "    \"quoted_status_id_str\",\n",
    "    \"quoted_status_id\",\n",
    "    \"id_str\",\n",
    "    \"quoted_status.in_reply_to_status_id_str\",\n",
    "    \"quoted_status.in_reply_to_status_id\",\n",
    "    \"quoted_status.in_reply_to_user_id_str\",\n",
    "    \"quoted_status.in_reply_to_user_id\",\n",
    "    \"quoted_status.id_str\",\n",
    "    \"quoted_status.id\",\n",
    "    \"quoted_status.user.id_str\",\n",
    "    \"quoted_status.user.id\",\n",
    "    \"quoted_status.quoted_status_id\",\n",
    "    \"quoted_status.quoted_status_id_str\",\n",
    "]].map(lambda x: float(x) if isinstance(x, str) else x).corrwith(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4089173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quoted_status.place.id    0.043506\n",
       "place.id                 -0.044059\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[[\n",
    "    \"quoted_status.place.id\",\n",
    "    \"place.id\",\n",
    "]].map(lambda x: int(x, base=16) if isinstance(x, str) else x).corrwith(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ed28a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Program Files\\Python310\\lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "quoted_status_permalink.expanded   -0.037841\n",
       "quoted_status_permalink.display     0.000148\n",
       "quoted_status_permalink.url              NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[[\n",
    "    \"quoted_status_permalink.expanded\",\n",
    "    \"quoted_status_permalink.display\",\n",
    "    \"quoted_status_permalink.url\",\n",
    "]].map(lambda x: len(x) if isinstance(x, str) else x).corrwith(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6396560b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "in_reply_to_status_id                 -0.050524\n",
       "is_quote_status                       -0.018314\n",
       "truncated                             -0.009665\n",
       "challenge_id                           0.001228\n",
       "quoted_status.retweet_count            0.017500\n",
       "quoted_status.favorite_count           0.017766\n",
       "quoted_status.quote_count              0.046755\n",
       "quoted_status.reply_count              0.007355\n",
       "quoted_status.user.friends_count      -0.019404\n",
       "quoted_status.user.listed_count        0.001474\n",
       "quoted_status.user.favourites_count   -0.050869\n",
       "quoted_status.user.statuses_count     -0.000199\n",
       "quoted_status.user.followers_count     0.007178\n",
       "user.listed_count                      0.078584\n",
       "user.favourites_count                  0.146453\n",
       "user.is_translator                     0.013591\n",
       "user.geo_enabled                       0.296986\n",
       "user.profile_background_tile           0.180543\n",
       "user.statuses_count                    0.281050\n",
       "user.profile_use_background_image     -0.129781\n",
       "user.default_profile                  -0.324203\n",
       "is_reply                              -0.216044\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.corrwith(y_train, numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fbea4f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at                      -0.026027\n",
       "quoted_status.created_at        -0.018908\n",
       "quoted_status.user.created_at    0.021092\n",
       "user.created_at                 -0.291983\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_cols = X_train[:10].apply(lambda col: pd.to_datetime(col, format=\"%a %b %d %H:%M:%S %z %Y\", errors=\"coerce\"))\n",
    "dt_cols = dt_cols.columns[dt_cols.notna().any()]\n",
    "\n",
    "pd.Series({\n",
    "    col: X_train[col].apply(lambda x: time.mktime(time.strptime(x, \"%a %b %d %H:%M:%S %z %Y\")) if pd.notnull(x) else pd.NA).corr(y_train)\n",
    "    for col in dt_cols\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "538f9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_len(x: typing.Any) -> int | float:\n",
    "    try:\n",
    "        return len(x)\n",
    "    except TypeError:\n",
    "        return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35844e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Program Files\\Python310\\lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\Abel\\AppData\\Local\\Temp\\ipykernel_13616\\4087167509.py:6: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  f\"len({col})\": X_train[col].apply(safe_len).fillna(0).corr(y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "len(created_at)                                                    NaN\n",
       "len(source)                                                  -0.084287\n",
       "len(in_reply_to_screen_name)                                 -0.217397\n",
       "len(text)                                                    -0.011660\n",
       "len(timestamp_ms)                                                  NaN\n",
       "len(quoted_status.extended_tweet.entities.urls)              -0.031582\n",
       "len(quoted_status.extended_tweet.entities.hashtags)          -0.000267\n",
       "len(quoted_status.extended_tweet.entities.user_mentions)     -0.015762\n",
       "len(quoted_status.extended_tweet.entities.symbols)            0.004725\n",
       "len(quoted_status.extended_tweet.full_text)                  -0.031543\n",
       "len(quoted_status.extended_tweet.display_text_range)         -0.027365\n",
       "len(quoted_status.created_at)                                -0.018283\n",
       "len(quoted_status.source)                                    -0.014854\n",
       "len(quoted_status.text)                                      -0.023169\n",
       "len(quoted_status.lang)                                      -0.018569\n",
       "len(quoted_status.entities.urls)                             -0.035785\n",
       "len(quoted_status.entities.hashtags)                          0.004730\n",
       "len(quoted_status.entities.user_mentions)                    -0.014256\n",
       "len(quoted_status.entities.symbols)                          -0.000859\n",
       "len(quoted_status.user.profile_image_url_https)              -0.018149\n",
       "len(quoted_status.user.profile_background_image_url)         -0.022667\n",
       "len(quoted_status.user.description)                          -0.019241\n",
       "len(quoted_status.user.created_at)                           -0.018283\n",
       "len(quoted_status.user.profile_background_image_url_https)   -0.022669\n",
       "len(quoted_status.user.screen_name)                          -0.024267\n",
       "len(quoted_status.user.profile_link_color)                   -0.018283\n",
       "len(quoted_status.user.translator_type)                      -0.012573\n",
       "len(quoted_status.user.profile_background_color)             -0.018283\n",
       "len(quoted_status.user.profile_sidebar_border_color)         -0.018283\n",
       "len(quoted_status.user.profile_text_color)                   -0.018283\n",
       "len(quoted_status.user.profile_image_url)                    -0.018147\n",
       "len(quoted_status.user.url)                                   0.001281\n",
       "len(quoted_status.user.profile_banner_url)                   -0.009256\n",
       "len(quoted_status.user.name)                                 -0.027843\n",
       "len(quoted_status.user.location)                             -0.007102\n",
       "len(quoted_status.user.profile_sidebar_fill_color)           -0.018283\n",
       "len(quoted_status_permalink.expanded)                        -0.019727\n",
       "len(entities.urls)                                            0.011930\n",
       "len(entities.hashtags)                                        0.073421\n",
       "len(entities.user_mentions)                                  -0.201323\n",
       "len(entities.symbols)                                         0.013301\n",
       "len(user.profile_image_url_https)                            -0.036512\n",
       "len(user.profile_background_image_url)                        0.275473\n",
       "len(user.description)                                         0.209465\n",
       "len(user.created_at)                                               NaN\n",
       "len(user.profile_background_image_url_https)                  0.275453\n",
       "len(user.profile_link_color)                                       NaN\n",
       "len(user.translator_type)                                     0.147421\n",
       "len(user.profile_background_color)                                 NaN\n",
       "len(user.profile_sidebar_border_color)                             NaN\n",
       "len(user.profile_text_color)                                       NaN\n",
       "len(user.profile_image_url)                                  -0.036512\n",
       "len(user.url)                                                 0.359260\n",
       "len(user.profile_banner_url)                                  0.206593\n",
       "len(user.location)                                            0.121540\n",
       "len(user.profile_sidebar_fill_color)                               NaN\n",
       "len(display_text_range)                                      -0.092617\n",
       "len(extended_tweet.entities.urls)                             0.124327\n",
       "len(extended_tweet.entities.hashtags)                         0.070111\n",
       "len(extended_tweet.entities.user_mentions)                   -0.111226\n",
       "len(extended_tweet.entities.symbols)                          0.009571\n",
       "len(extended_tweet.full_text)                                -0.007871\n",
       "len(extended_tweet.display_text_range)                       -0.009665\n",
       "len(quoted_status.extended_entities.media)                    0.013987\n",
       "len(quoted_status.entities.media)                             0.012334\n",
       "len(quoted_status.display_text_range)                        -0.009546\n",
       "len(full_text)                                               -0.007709\n",
       "len(source.url)                                              -0.059835\n",
       "len(source.name)                                             -0.139366\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_cols = X_train[:10].apply(lambda col: col.map(safe_len))\n",
    "len_cols = len_cols.columns[len_cols.notna().any()]\n",
    "\n",
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(pd.Series({\n",
    "        f\"len({col})\": X_train[col].apply(safe_len).fillna(0).corr(y_train)\n",
    "        for col in len_cols\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1cb4b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train[\"full_text\"].apply(safe_len).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b6dd42ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_kaggle[\"full_text\"].apply(safe_len).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7ab0cd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409 vs 279; 116 common, 163 new. Average len: 78.23 vs 78.26\n",
      "26282 vs 19130; 5590 common, 13540 new. Average len: 10.56 vs 10.55\n",
      "12868 vs 9461; 3762 common, 5699 new. Average len: 10.32 vs 10.29\n",
      "12995 vs 9554; 3805 common, 5749 new. Average len: 12.71 vs 12.69\n"
     ]
    }
   ],
   "source": [
    "for col in [\n",
    "    # \"full_text\",\n",
    "    # \"user.description\",\n",
    "    \"source\",\n",
    "    \"in_reply_to_screen_name\",\n",
    "    \"quoted_status.user.screen_name\",\n",
    "    \"quoted_status.user.name\",\n",
    "]:\n",
    "    train_values = set(X_train[col].unique())\n",
    "    infer_values = set(X_kaggle[col].unique())\n",
    "    print(\n",
    "        f\"{len(train_values)} vs {len(infer_values)}; {len(train_values & infer_values)} common, {len(infer_values - train_values)} new. \"\n",
    "        f\"Average len: {X_train[col].dropna().map(len).mean():.2f} vs {X_kaggle[col].dropna().map(len).mean():.2f}\"\n",
    "    )\n",
    "    del train_values, infer_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda51842",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5be1585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Made this a class to hold all the caches. It may resemble an nn.Module, but isn't one!\n",
    "class FeatureExtractor:\n",
    "    training: bool\n",
    "    device: torch.device\n",
    "    means: pd.Series | None\n",
    "    stds: pd.Series | None\n",
    "    afm_cache: dict[tuple[str, str], float]\n",
    "    text_encoder_name: str | None\n",
    "    text_tokenizer: nn.Module | None\n",
    "    text_encoder: nn.Module | None\n",
    "    text_enc_cache_path: pathlib.Path | None\n",
    "    \n",
    "    def __init__(self, text_encoder_name: str | None = None, text_enc_cache_path: pathlib.Path | None = None, device: torch.device = device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.means = None\n",
    "        self.stds = None\n",
    "        self.afm_cache = {}\n",
    "        self.text_enc_cache_path = text_enc_cache_path\n",
    "        \n",
    "        self.text_encoder_name = text_encoder_name\n",
    "        self.text_tokenizer = None\n",
    "        self.text_encoder = None\n",
    "        \n",
    "        if text_encoder_name is not None:\n",
    "            self.text_tokenizer = AutoTokenizer.from_pretrained(text_encoder_name)\n",
    "            if hasattr(self.text_tokenizer, \"to\"):  # Distilbert doesn't, apprently\n",
    "                self.text_tokenizer = self.text_tokenizer.to(self.device)\n",
    "            self.text_encoder = AutoModel.from_pretrained(text_encoder_name).to(self.device)\n",
    "        \n",
    "        self.train()\n",
    "    \n",
    "    def train(self):\n",
    "        self.training = True\n",
    "    \n",
    "    def eval(self):\n",
    "        self.training = False\n",
    "    \n",
    "    def state_dict(self):\n",
    "        return {\n",
    "            \"means\": self.means,\n",
    "            \"stds\": self.stds,\n",
    "            \"afm_cache\": self.afm_cache,\n",
    "        }\n",
    "    \n",
    "    def load_state_dict(self, state_dict):\n",
    "        self.means = state_dict[\"means\"]\n",
    "        self.stds = state_dict[\"stds\"]\n",
    "        self.afm_cache = state_dict[\"afm_cache\"]\n",
    "    \n",
    "    def extract(self, df: pd.DataFrame, override_cache: bool = False) -> torch.Tensor:\n",
    "        md_cols: list[pd.Series] = []\n",
    "\n",
    "        for fn, col_name in tqdm(self.METADATA_FIELDS, desc=\"Extracting metadata\"):\n",
    "            md_cols.append(fn(self, df[col_name]))\n",
    "        \n",
    "        md: pd.DataFrame = pd.concat(md_cols, axis=1)\n",
    "        \n",
    "        # The second case shouldn't be triggered, but sometimes the preprocessor used during training is lost\n",
    "        if self.training:\n",
    "            self.means = md.mean().fillna(0)\n",
    "            self.stds = md.std().fillna(1)\n",
    "        \n",
    "        assert self.means is not None and self.stds is not None, \"You forgot to train/load the feature extractor\"\n",
    "\n",
    "        md = (md - self.means) / self.stds\n",
    "\n",
    "        md_tensor = torch.from_numpy(md.to_numpy()).float().to(self.device)\n",
    "        \n",
    "        # return torch.cat([md_tensor, torch.zeros(len(df), self.dim_txt, device=self.device)], dim=1)\n",
    "        \n",
    "        txt_cols: list[torch.Tensor] = []\n",
    "        \n",
    "        if self.text_enc_cache_path is None:\n",
    "            for col_name in self.TEXT_FIELDS:\n",
    "                txt_cols.append(self.embed_texts(df[col_name]))\n",
    "        else:\n",
    "            cf = self.text_enc_cache_path / (\"train.ckpt\" if self.training else \"infer.ckpt\")\n",
    "            cf.parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            if cf.exists() and not override_cache:\n",
    "                encodings = torch.load(cf)\n",
    "                for col_name in self.TEXT_FIELDS:\n",
    "                    txt_cols.append(encodings[col_name].to(self.device))\n",
    "            else:\n",
    "                for col_name in self.TEXT_FIELDS:\n",
    "                    txt_cols.append(self.embed_texts(df[col_name]))\n",
    "                \n",
    "                torch.save({\n",
    "                    field: embedding.cpu().detach()\n",
    "                    for field, embedding in zip(self.TEXT_FIELDS, txt_cols)\n",
    "                }, cf)\n",
    "        \n",
    "        txt_tensor = torch.cat(txt_cols, dim=1)\n",
    "        \n",
    "        return torch.cat([md_tensor, txt_tensor], dim=1)\n",
    "    \n",
    "    @property\n",
    "    def dim(self) -> int:\n",
    "        return self.dim_md + self.dim_txt\n",
    "    \n",
    "    @property\n",
    "    def dim_md(self) -> int:\n",
    "        return len(self.METADATA_FIELDS)\n",
    "    \n",
    "    @property\n",
    "    def dim_txt(self) -> int:\n",
    "        return len(self.TEXT_FIELDS) * self.embed_size\n",
    "    \n",
    "    @property\n",
    "    def embed_size(self) -> int:\n",
    "        return self.text_encoder.config.hidden_size\n",
    "    \n",
    "    def apply_fill_mean(\n",
    "        self,\n",
    "        col: pd.Series,\n",
    "        func: typing.Callable[[typing.Any], typing.Any],\n",
    "    ) -> pd.Series:\n",
    "        col = col.map(func, na_action=\"ignore\")\n",
    "        \n",
    "        key = (col.name, func.__name__)\n",
    "        if self.training:\n",
    "            self.afm_cache[key] = col.mean()\n",
    "        \n",
    "        return col.fillna(self.afm_cache[key])\n",
    "    \n",
    "    def md_bool(self, col: pd.Series) -> pd.Series:\n",
    "        return col.map(lambda x: (1 if x else -1), na_action=\"ignore\").fillna(0)\n",
    "\n",
    "    def md_len(self, col: pd.Series) -> pd.Series:\n",
    "        return col.map(len, na_action=\"ignore\").fillna(0)\n",
    "\n",
    "    def md_time(self, col: pd.Series) -> pd.Series:\n",
    "        return self.apply_fill_mean(col, lambda x: time.mktime(time.strptime(x, \"%a %b %d %H:%M:%S %z %Y\")))\n",
    "\n",
    "    def md_num(self, col: pd.Series) -> pd.Series:\n",
    "        return self.apply_fill_mean(col, pd.to_numeric)\n",
    "\n",
    "    def md_place(self, col: pd.Series) -> pd.Series:\n",
    "        return col.map(lambda x: int(x, 16), na_action=\"ignore\").fillna(0)\n",
    "    \n",
    "    METADATA_FIELDS: list[tuple[typing.Callable[[FeatureExtractor, pd.Series], pd.Series], str]] = [\n",
    "        (md_bool, \"is_quote_status\"),\n",
    "        (md_bool, \"is_reply\"),\n",
    "        (md_bool, \"possibly_sensitive\"),\n",
    "        (md_bool, \"quoted_status.user.verified\"),\n",
    "        (md_bool, \"user.is_translator\"),\n",
    "        (md_bool, \"user.geo_enabled\"),\n",
    "        (md_bool, \"user.profile_use_background_image\"),\n",
    "        (md_bool, \"user.default_profile\"),\n",
    "        \n",
    "        (md_len, \"full_text\"),\n",
    "        (md_len, \"source.name\"),\n",
    "        (md_len, \"in_reply_to_screen_name\"),\n",
    "        (md_len, \"quoted_status.extended_tweet.entities.urls\"),\n",
    "        (md_len, \"quoted_status.extended_tweet.entities.user_mentions\"),\n",
    "        (md_len, \"quoted_status.extended_tweet.full_text\"),\n",
    "        (md_len, \"quoted_status.entities.urls\"),\n",
    "        (md_len, \"quoted_status.user.profile_image_url_https\"),\n",
    "        (md_len, \"quoted_status.user.profile_background_image_url\"),\n",
    "        (md_len, \"quoted_status.user.profile_background_image_url_https\"),\n",
    "        (md_len, \"quoted_status.user.screen_name\"),\n",
    "        (md_len, \"quoted_status.user.name\"),\n",
    "        (md_len, \"entities.hashtags\"),\n",
    "        (md_len, \"entities.user_mentions\"),\n",
    "        (md_len, \"user.profile_image_url_https\"),\n",
    "        (md_len, \"user.profile_background_image_url\"),\n",
    "        (md_len, \"user.description\"),\n",
    "        (md_len, \"user.translator_type\"),\n",
    "        (md_len, \"user.url\"),\n",
    "        (md_len, \"user.profile_banner_url\"),\n",
    "        (md_len, \"user.location\"),\n",
    "        (md_len, \"display_text_range\"),\n",
    "        (md_len, \"extended_tweet.entities.urls\"),\n",
    "        (md_len, \"extended_tweet.entities.hashtags\"),\n",
    "        (md_len, \"extended_tweet.entities.user_mentions\"),\n",
    "        (md_len, \"quoted_status_permalink.expanded\"),\n",
    "        \n",
    "        (md_time, \"created_at\"),\n",
    "        (md_time, \"user.created_at\"),\n",
    "        (md_time, \"quoted_status.created_at\"),\n",
    "        (md_time, \"quoted_status.user.created_at\"),\n",
    "        \n",
    "        (md_num, \"user.statuses_count\"),\n",
    "        (md_num, \"user.listed_count\"),\n",
    "        (md_num, \"user.favourites_count\"),\n",
    "        (md_num, \"user.profile_background_tile\"),\n",
    "        (md_num, \"quoted_status.quote_count\"),\n",
    "        (md_num, \"quoted_status.user.followers_count\"),\n",
    "        (md_num, \"quoted_status.user.favourites_count\"),\n",
    "        (md_num, \"in_reply_to_status_id\"),\n",
    "        \n",
    "        (md_place, \"quoted_status.place.id\"),\n",
    "        (md_place, \"place.id\"),\n",
    "    ]\n",
    "\n",
    "    def embed_texts(\n",
    "        self,\n",
    "        texts: pd.Series,\n",
    "        batch_size: int = 64,\n",
    "        progress: bool = True\n",
    "    ) -> torch.Tensor:\n",
    "        tokenizer = self.text_tokenizer\n",
    "        encoder = self.text_encoder\n",
    "        encoder.eval()\n",
    "\n",
    "        all_embeddings = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_offsets = range(0, len(texts), batch_size)\n",
    "            if progress:\n",
    "                batch_offsets = tqdm(batch_offsets, desc=f\"Embedding {texts.name or '<unnamed>'}\")\n",
    "            for i in batch_offsets:\n",
    "                batch_texts = texts.iloc[i:i + batch_size]\n",
    "                nonna = batch_texts.notna() & batch_texts.str.len().gt(0)\n",
    "\n",
    "                tokenized = tokenizer(\n",
    "                    batch_texts[nonna].tolist(),\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    return_tensors=\"pt\",\n",
    "                ).to(self.device)\n",
    "\n",
    "                outputs: transformers.modeling_outputs.BaseModelOutput = encoder(**tokenized)\n",
    "                last_hidden: torch.Tensor = outputs.last_hidden_state\n",
    "                mask: torch.Tensor = tokenized[\"attention_mask\"].unsqueeze(-1)\n",
    "                \n",
    "                masked_hidden = last_hidden * mask\n",
    "                summed = masked_hidden.sum(dim=1)\n",
    "                counts = mask.sum(dim=1)\n",
    "                embeddings = torch.zeros(len(batch_texts), last_hidden.shape[2], device=self.device)\n",
    "                nonna = nonna.reset_index(drop=True)\n",
    "                embeddings[nonna[nonna].index] = (summed / counts)\n",
    "\n",
    "                all_embeddings.append(embeddings)\n",
    "\n",
    "        return torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "    TEXT_FIELDS: list[str | typing.Callable[[pd.DataFrame], pd.Series]] = [\n",
    "        \"full_text\",\n",
    "        \"user.description\",\n",
    "        # lambda df: df.apply(lambda x: \"via: {0}, reply: @{1}; quote: @{2} {3}\".format(x[\"source.name\"], x[\"in_reply_to_screen_name\"], x[\"quoted_status.user.screen_name\"], x[\"quoted_status.user.name\"])),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1bc90d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    features: torch.Tensor\n",
    "    labels: torch.Tensor\n",
    "    device: torch.device\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_extractor: FeatureExtractor,\n",
    "        df: pd.DataFrame,\n",
    "        labels: pd.Series,\n",
    "        device: torch.device = device,\n",
    "    ):\n",
    "        self.features = feature_extractor.extract(df)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"features\": self.features[idx],\n",
    "            \"label\": self.labels[idx],\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    features = torch.stack([x[\"features\"] for x in batch])\n",
    "    labels = torch.stack([x[\"label\"] for x in batch])\n",
    "    return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "af4a722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "\n",
    "class TweetClassifier(nn.Module):\n",
    "    num_features: int\n",
    "    dropout: nn.Module\n",
    "    fc1: nn.Module\n",
    "    fc2: nn.Module\n",
    "    fc3: nn.Module\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_features: int,\n",
    "        hidden_dim: int = 512,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_features = num_features\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc1 = nn.Linear(num_features, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, NUM_CLASSES)\n",
    "    \n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return next(self.parameters()).device\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Returns dict with:\n",
    "            \"logits\": tensor [batch_size, num_classes]\n",
    "            \"probs\": tensor [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        batch_size = len(x)\n",
    "        \n",
    "        assert x.shape == (batch_size, self.num_features)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        logits = self.fc3(x)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        return {\n",
    "            \"logits\": logits,\n",
    "            \"probs\": probs,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c7a47ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: TweetClassifier,\n",
    "    train_ds: Dataset,\n",
    "    val_ds: Dataset,\n",
    "    epochs: int = 3,\n",
    "    lr: float = 2e-4,\n",
    "    weight_decay: float = 0.01,\n",
    "    max_grad_norm: float = 1.0,\n",
    "    device: torch.device = device,\n",
    "    batch_size: int = 32,\n",
    "    optimizer: torch.optim.Optimizer | None = None,\n",
    "    checkpoints_path: pathlib.Path | str | None = \".\",\n",
    "    return_best: bool = False,\n",
    ") -> TweetClassifier:\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    \n",
    "    model.to(device)\n",
    "    if optimizer is None:\n",
    "        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_file: pathlib.Path | None = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{epochs}\")\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        status_bar = tqdm(train_loader, desc=\"Training\")\n",
    "\n",
    "        for features, labels in status_bar:\n",
    "            features: torch.Tensor\n",
    "            labels: torch.Tensor\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            out = model(features)\n",
    "            logits = out[\"logits\"]\n",
    "            \n",
    "            loss: torch.Tensor = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            status_bar.set_postfix({\"loss\": total_loss / (status_bar.n + 1)})\n",
    "        \n",
    "        print(f\"Train Loss: {total_loss / len(train_loader):.4f}\")\n",
    "        \n",
    "        val_metrics = evaluate_model(\n",
    "            model=model,\n",
    "            val_ds=val_ds,\n",
    "            device=device,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "        print(f\"Val Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['acc']:.4f}\")\n",
    "\n",
    "        if checkpoints_path is not None:\n",
    "            ckpt = pathlib.Path(checkpoints_path) / f\"epoch_{epoch:02}.pt\"\n",
    "            torch.save(model.state_dict(), ckpt)\n",
    "            print(f\"Checkpoint saved to {ckpt}\")\n",
    "            \n",
    "            if val_metrics[\"loss\"] < best_val_loss:\n",
    "                best_val_loss = val_metrics[\"loss\"]\n",
    "                best_model_file = ckpt\n",
    "\n",
    "    if return_best and best_model_file is not None:\n",
    "        print(f\"Best model: {best_model_file}\")\n",
    "        model.load_state_dict(torch.load(best_model_file))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    model: TweetClassifier,\n",
    "    val_ds: Dataset,\n",
    "    device: torch.device = device,\n",
    "    batch_size: int = 32,\n",
    ") -> tuple[float, float]:\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        status_bar = tqdm(val_loader, desc=\"Evaluating\")\n",
    "        \n",
    "        for features, labels in status_bar:\n",
    "            features: torch.Tensor\n",
    "            labels: torch.Tensor\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            out = model(features)\n",
    "            logits: torch.Tensor = out[\"logits\"]\n",
    "            \n",
    "            loss: torch.Tensor = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            count += labels.size(0)\n",
    "            \n",
    "            status_bar.set_postfix({\"loss\": total_loss / (status_bar.n + 1), \"acc\": correct / count})\n",
    "\n",
    "    return {\n",
    "        \"loss\": total_loss / len(val_loader),\n",
    "        \"acc\": correct / count,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "558a176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_with_model(\n",
    "    model: TweetClassifier,\n",
    "    feature_extractor: FeatureExtractor,\n",
    "    df: pd.DataFrame,\n",
    "    out_file: pathlib.Path | str | None = None,\n",
    "    device: torch.device = device,\n",
    "    batch_size: int = 32,\n",
    ") -> torch.Tensor:\n",
    "    feature_extractor.eval()\n",
    "    \n",
    "    data_loader = DataLoader(\n",
    "        TweetDataset(feature_extractor, df, torch.zeros(len(df), dtype=torch.long, device=device), device=device),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    predictions = torch.zeros(len(df), dtype=torch.long)\n",
    "    cur_idx = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, _ in tqdm(data_loader, desc=\"Inferring\"):\n",
    "            features: torch.Tensor\n",
    "            features = features.to(device)\n",
    "\n",
    "            out = model(features)\n",
    "            logits: torch.Tensor = out[\"logits\"].cpu()\n",
    "            \n",
    "            predictions[cur_idx:cur_idx+len(features)] = logits.argmax(dim=-1)\n",
    "            cur_idx += len(features)\n",
    "    \n",
    "    if out_file is not None:\n",
    "        output = pd.concat([df[\"challenge_id\"], pd.DataFrame(predictions)], axis=1, ignore_index=True)\n",
    "        output.columns = [\"ID\", \"Prediction\"]\n",
    "        output.to_csv(out_file, index=False)\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4f2d9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_text_encoder(text_encoder_name: str):\n",
    "    print(f\"\\n===== [ {text_encoder_name} ] =====\\n\")\n",
    "    \n",
    "    model_folder = pathlib.Path(\"./models/v8/\") / text_encoder_name.split(\"/\")[-1]\n",
    "    model_folder.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    feature_extractor = FeatureExtractor(text_encoder_name=text_encoder_name, text_enc_cache_path=model_folder / \"text_enc_cache\", device=device)\n",
    "\n",
    "    feature_extractor.train()\n",
    "    full_train_ds = TweetDataset(feature_extractor, X_train, y_train, device=device)\n",
    "    \n",
    "    torch.save(feature_extractor.state_dict(), model_folder / \"feature_extractor.ckpt\")\n",
    "\n",
    "    train_ds, val_ds = random_split(full_train_ds, [0.9, 0.1])\n",
    "    \n",
    "    model = TweetClassifier(\n",
    "        num_features=feature_extractor.dim,\n",
    "        hidden_dim=512,\n",
    "    ).to(device)\n",
    "    \n",
    "    model = train_model(model, train_ds, val_ds, lr=2e-4, epochs=10, batch_size=64, device=device, checkpoints_path=model_folder, return_best=True)\n",
    "    torch.save(model.state_dict(), model_folder / \"best_model.ckpt\")\n",
    "    torch.cuda.empty_cache()\n",
    "    infer_with_model(model, feature_extractor, X_kaggle, batch_size=64, device=device, out_file=model_folder / \"predictions-v8.csv\")\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4f656ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== [ distilbert/distilbert-base-cased ] =====\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting metadata:  19%|        | 9/48 [00:00<00:01, 29.72it/s]C:\\Users\\Abel\\AppData\\Local\\Temp\\ipykernel_13616\\1823344070.py:131: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return col.map(len, na_action=\"ignore\").fillna(0)\n",
      "Extracting metadata: 100%|| 48/48 [00:08<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 2179/2179 [00:12<00:00, 179.88it/s, loss=0.469]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 243/243 [00:00<00:00, 299.84it/s, loss=0.453, acc=0.806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4254, Acc: 0.8056\n",
      "Checkpoint saved to models\\v8\\distilbert-base-cased\\epoch_01.pt\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 2179/2179 [00:12<00:00, 174.38it/s, loss=0.43] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 243/243 [00:00<00:00, 263.34it/s, loss=0.416, acc=0.814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4109, Acc: 0.8136\n",
      "Checkpoint saved to models\\v8\\distilbert-base-cased\\epoch_02.pt\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 2179/2179 [00:12<00:00, 174.80it/s, loss=0.416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 243/243 [00:00<00:00, 297.21it/s, loss=0.444, acc=0.821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3928, Acc: 0.8211\n",
      "Checkpoint saved to models\\v8\\distilbert-base-cased\\epoch_03.pt\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 2179/2179 [00:12<00:00, 172.72it/s, loss=0.406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 243/243 [00:00<00:00, 284.28it/s, loss=0.401, acc=0.826]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3909, Acc: 0.8262\n",
      "Checkpoint saved to models\\v8\\distilbert-base-cased\\epoch_04.pt\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 2179/2179 [00:12<00:00, 168.79it/s, loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 243/243 [00:00<00:00, 288.19it/s, loss=0.401, acc=0.822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4007, Acc: 0.8218\n",
      "Checkpoint saved to models\\v8\\distilbert-base-cased\\epoch_05.pt\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 2179/2179 [00:13<00:00, 162.89it/s, loss=0.383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 243/243 [00:00<00:00, 269.21it/s, loss=0.391, acc=0.839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3720, Acc: 0.8389\n",
      "Checkpoint saved to models\\v8\\distilbert-base-cased\\epoch_06.pt\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 2179/2179 [00:12<00:00, 168.34it/s, loss=0.369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 243/243 [00:00<00:00, 284.71it/s, loss=0.397, acc=0.836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3723, Acc: 0.8358\n",
      "Checkpoint saved to models\\v8\\distilbert-base-cased\\epoch_07.pt\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 2179/2179 [00:14<00:00, 151.13it/s, loss=0.358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 243/243 [00:01<00:00, 221.55it/s, loss=0.366, acc=0.842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3600, Acc: 0.8416\n",
      "Checkpoint saved to models\\v8\\distilbert-base-cased\\epoch_08.pt\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 2179/2179 [00:13<00:00, 158.91it/s, loss=0.347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 243/243 [00:00<00:00, 278.16it/s, loss=0.377, acc=0.839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3598, Acc: 0.8387\n",
      "Checkpoint saved to models\\v8\\distilbert-base-cased\\epoch_09.pt\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|| 2179/2179 [00:13<00:00, 165.80it/s, loss=0.334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 243/243 [00:00<00:00, 263.14it/s, loss=0.389, acc=0.844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.3537, Acc: 0.8444\n",
      "Checkpoint saved to models\\v8\\distilbert-base-cased\\epoch_10.pt\n",
      "Best model: models\\v8\\distilbert-base-cased\\epoch_10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting metadata: 100%|| 48/48 [00:06<00:00,  7.96it/s]\n",
      "Embedding full_text: 100%|| 1616/1616 [09:16<00:00,  2.90it/s]\n",
      "Embedding user.description: 100%|| 1616/1616 [04:15<00:00,  6.32it/s]\n",
      "C:\\Users\\Abel\\AppData\\Local\\Temp\\ipykernel_13616\\548484398.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
      "Inferring: 100%|| 1616/1616 [00:02<00:00, 693.28it/s]\n"
     ]
    }
   ],
   "source": [
    "run_with_text_encoder(\"distilbert/distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4ad414f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting metadata:  12%|        | 6/48 [00:00<00:00, 47.89it/s]C:\\Users\\Abel\\AppData\\Local\\Temp\\ipykernel_13616\\3111951114.py:112: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  return col.map(len, na_action=\"ignore\").fillna(0)\n",
      "Extracting metadata: 100%|| 48/48 [00:05<00:00,  8.87it/s]\n",
      "C:\\Users\\Abel\\AppData\\Local\\Temp\\ipykernel_13616\\548484398.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.long, device=device)\n",
      "Inferring: 100%|| 1616/1616 [00:02<00:00, 752.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0,  ..., 1, 1, 0])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_folder = pathlib.Path(\"./models/v8/distilbert-base-cased\")\n",
    "# feature_extractor = FeatureExtractor(text_encoder_name=\"distilbert/distilbert-base-cased\", text_enc_cache_path=model_folder / \"text_enc_cache\", device=device)\n",
    "# feature_extractor.load_state_dict(torch.load(model_folder / \"feature_extractor.ckpt\"))\n",
    "# model = TweetClassifier(\n",
    "#     num_features=feature_extractor.dim,\n",
    "#     hidden_dim=512,\n",
    "# ).to(device)\n",
    "# model.load_state_dict(torch.load(model_folder / \"epoch_10.pt\"))\n",
    "# infer_with_model(model, feature_extractor, X_kaggle, batch_size=64, device=device, out_file=model_folder / \"predictions-v8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6af070",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_with_text_encoder(\"camembert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777371d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_with_text_encoder(\"Geotrend/distilbert-base-en-fr-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff529c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_with_text_encoder(\"flaubert/flaubert_base_cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6587727",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_with_text_encoder(\"flaubert/flaubert_small_cased\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
